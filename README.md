# Machine_Learning_Project

Libraies used - https://scikit-learn.org/stable/ https://scipy.org/ https://matplotlib.org/ https://xgboost.readthedocs.io/en/stable/install.html https://pandas.pydata.org/

# Research to boost overall performance by problem modification shown in this figure:


# Research Objectives:

 
 #Identification and selection of an open dataset.

• Investigation and Evaluation of a pre-processing method to change the problem domain of regression into classification.

• Application of different types of regression-based algorithms.

• Change the problem domain from regression to classification.

• Implementation of several classifier-based algorithms.

• Review of the overall performance.

Reg_to_clas


# Strategies and Methods' Flow diagram:


# Concept



# Three Open Datasets Used to check the performance.

1. [Frames Per second] - https://www.openml.org/search?type=data&id=42737&sort=runs&status=active
  
2. [California Hosuing] - https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html
  
3. [Diabetes Dataset] - https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html

   
Table Dataset size

References:

[1] H. Liu, F. Hussain, C. L. Tan, and M. Dash, “Discretization: An enabling technique,” Data mining and knowledge discovery, vol. 6, pp. 393–423, 2002. [Online]. Available: https://doi.org/10.1023/A:1016304305535

[2] I. Sarker, “Machine learning: Algorithms, real-world applications and research direc- tions,” SN Computer Science, vol. 2, 03 2021.

[3] P. Ranganathan and N. J. Gogtay, “An introduction to statistics–data types, distributions and summarizing data,” Indian journal of critical care medicine: peer-reviewed, official publication of Indian Society of Critical Care Medicine, vol. 23, no. Suppl 2, p. S169, 2019.

[4] S. Mat Roni, M. K. Merga, and J. E. Morris, Data Types and Samples. Singapore: Springer Singapore, 2020, pp. 39–45. [Online]. Available: https: //doi.org/10.1007/978-981-13-9132-3_4

[5] S. García, J. Luengo, and F. Herrera, Data Preprocessing in Data Mining, ser. Intelligent Systems Reference Library. Springer International Publishing, 2014. [Online]. Available: https://books.google.de/books?id=SbFkBAAAQBAJ

[6] G. Rebala, A. Ravi, and S. Churiwala, Machine Learning Definition and Basics. Cham: Springer International Publishing, 2019, pp. 1–17. [Online]. Available: https://doi.org/10.1007/978-3-030-15729-6_1

[7] M. Mohammed, M. B. Khan, and E. B. M. Bashier, Machine learning: algorithms and applications. Crc Press, 2016.

[8] J. Dougherty, R. Kohavi, and M. Sahami, “Supervised and unsupervised discretization of continuous features,” in Machine learning proceedings 1995. Elsevier, 1995, pp. 194–202.

[9] L. Torgo and J. Gama, “Regression by classification,” in Advances in Artificial Intelli- gence: 13th Brazilian Symposium on Artificial Intelligence, SBIA’96 Curitiba, Brazil, October 23–25, 1996 Proceedings 13. Springer, 1996, pp. 51–60.

[10] R. Salman and V. Kecman, “Regression as classification,” in 2012 Proceedings of IEEE Southeastcon. IEEE, 2012, pp. 1–6. 32

[11] J. Vanschoren, J. N. van Rijn, B. Bischl, and L. Torgo, “Openml: networked science in machine learning,” SIGKDD Explorations, vol. 15, no. 2, pp. 49–60, 2013. [Online]. Available: http://doi.acm.org/10.1145/2641190.264119

[12] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blon- del, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, “Scikit-learn: Machine learning in Python,” Journal of Machine Learning Research, vol. 12, pp. 2825–2830, 2011.

[13] J. D. Hunter, “Matplotlib: A 2d graphics environment,” Computing in Science & Engi- neering, vol. 9, no. 3, pp. 90–95, 2007.

[14] M. L. Waskom, “seaborn: statistical data visualization,” Journal of Open Source Software, vol. 6, no. 60, p. 3021, 2021. [Online]. Available: https://doi.org/10.21105/joss.03021

[15] Wes McKinney, “Data Structures for Statistical Computing in Python,” in Proceedings of the 9th Python in Science Conference, Stéfan van der Walt and Jarrod Millman, Eds., 2010, pp. 56 – 61.

[16] T. pandas development team, “pandas-dev/pandas: Pandas,” Feb. 2020. [Online]. Available: https://doi.org/10.5281/zenodo.3509134

[17] P. Virtanen, R. Gommers, T. E. Oliphant, M. Haberland, T. Reddy, D. Cournapeau, E. Burovski, P. Peterson, W. Weckesser, J. Bright, S. J. van der Walt, M. Brett, J. Wil- son, K. J. Millman, N. Mayorov, A. R. J. Nelson, E. Jones, R. Kern, E. Larson, C. J. Carey, ̇I. Polat, Y. Feng, E. W. Moore, J. VanderPlas, D. Laxalde, J. Perktold, R. Cimrman, I. Henriksen, E. A. Quintero, C. R. Harris, A. M. Archibald, A. H. Ribeiro, F. Pedregosa, P. van Mulbregt, and SciPy 1.0 Contributors, “SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python,” Nature Methods, vol. 17, pp. 261–272, 2020.

[18] L. Breiman, “Random forests,” Machine learning, vol. 45, pp. 5–32, 2001.

[19] T. Chen and C. Guestrin, “XGBoost: A scalable tree boosting system,” in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD ’16. New York, NY, USA: ACM, 2016, pp. 785–794. [Online]. Available: http://doi.acm.org/10.1145/2939672.2939785

[20] I. Muraina, O. Adesanya, and S. Abam, “Data analytics evaluation metrics essentials: Measuring model performance in classification and regression,” 08 2023.
